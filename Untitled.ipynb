{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325afe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "from random import choice\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.applications import LeNet\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee3baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "train_dir= os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir= os.path.join(data_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51064aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"random_image = choice(train_data)\n",
    "\n",
    "with Image.open(random_image) as img : \n",
    "    m, n= img.size\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Random Image from {random_image_path} (Height={n}, Width={m})\")\n",
    "    plt.show()\n",
    "    \n",
    "print(f\"Randomly selected image dimensions: height (n) = {n}, width (m) = {m}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting with Lenet architecture \n",
    "#data preprocessing \n",
    "#define the image dimensions suitable for LeNet \n",
    "img_height, img_width = 28, 28\n",
    "\n",
    "# define data eugementation parameters ( opitional)\n",
    "\n",
    "train_datagen = ImageDataGenerator (rescale = 1./255, \n",
    "                                   shear_range =0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale= 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                   target_size=(img_height,img_width),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   color_mode=\"grayscale\")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, \n",
    "                                                   target_size=(img_height,img_width),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"binary\",\n",
    "                                               color_mode=\"grayscale\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                   target_size=(img_height,img_width),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                 color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5c003",
   "metadata": {},
   "source": [
    "# model building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbbe99",
   "metadata": {},
   "source": [
    "## LeNet architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5(input_shape=(28, 28, 1), num_classes=1):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(6, (5, 5), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(16, (5, 5), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(120, activation='relu'),\n",
    "        layers.Dense(84, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lenet5(input_shape=(img_width, img_height, 1))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73290ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,  # Adjust epochs as needed\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'history' is the output from model.fit()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"pneumonia_classification_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5686c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "import os\n",
    "print(\"Files in the current directory:\")\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"pneumonia_classification_model.h5\")\n",
    "\n",
    "# Get a random batch from the test generator\n",
    "batch = next(iter(test_generator))\n",
    "\n",
    "# Select a random index from the batch\n",
    "random_index = random.randint(0, len(batch[0]) - 1)\n",
    "\n",
    "# Get the image and corresponding true label\n",
    "random_image = batch[0][random_index]  # This is the image\n",
    "true_label = batch[1][random_index]  # This is the true label\n",
    "\n",
    "# Display the random image\n",
    "plt.imshow(random_image.squeeze(), cmap='gray')\n",
    "plt.title(\"Random Test Image\")\n",
    "plt.show()\n",
    "\n",
    "# Make a prediction using the model\n",
    "prediction = model.predict(np.expand_dims(random_image, axis=0))\n",
    "\n",
    "# Convert prediction to a class (binary: 0 or 1)\n",
    "predicted_class = int(prediction[0] > 0.5)  # Assuming 0.5 as the threshold for binary classification\n",
    "\n",
    "# Determine the name of the class (0 = Normal, 1 = Pneumonia)\n",
    "class_names = [\"Normal\", \"Pneumonia\"]\n",
    "\n",
    "# Print the prediction and the true label\n",
    "print(f\"Predicted Class: {class_names[predicted_class]}\")\n",
    "print(f\"True Label: {class_names[int(true_label)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68439cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Define the data directories\n",
    "data_dir = \"./data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Define image dimensions for AlexNet\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators with the correct target size for AlexNet\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "     class_mode=\"binary\")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, \n",
    "                                                   target_size=(img_height,img_width),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"binary\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                   target_size=(img_height,img_width),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"binary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d48caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 2. AlexNet Architecture\n",
    "\n",
    "def alexnet(input_shape=(224, 224, 3), num_classes=1):\n",
    "    model = models.Sequential([\n",
    "        # First convolutional layer\n",
    "        layers.Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((3, 3), strides=2),\n",
    "\n",
    "        # Second convolutional layer\n",
    "        layers.Conv2D(256, (5, 5), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D((3, 3), strides=2),\n",
    "\n",
    "        # Third, fourth, and fifth convolutional layers\n",
    "        layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "        layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D((3, 3), strides=2),\n",
    "\n",
    "        # Fully connected layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        # Output layer for binary classification\n",
    "        layers.Dense(num_classes, activation='sigmoid')  # Use sigmoid for binary classification\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45d685",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile the AlexNet model\n",
    "model = alexnet(input_shape=(img_width, img_height, 3))\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,  # Adjust as needed\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e84ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random batch from the test generator\n",
    "batch = next(iter(test_generator))\n",
    "\n",
    "# Select a random index from the batch\n",
    "random_index = random.randint(0, len(batch[0]) - 1)\n",
    "\n",
    "# Get the image and corresponding true label\n",
    "random_image = batch[0][random_index]\n",
    "true_label = batch[1][random_index]\n",
    "\n",
    "# Display the random image\n",
    "plt.imshow(random_image)\n",
    "plt.title(\"Random Test Image\")\n",
    "plt.show()\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(np.expand_dims(random_image, axis=0))\n",
    "\n",
    "# Determine the predicted class\n",
    "predicted_class = int(prediction[0] > 0.5)  # 0.5 threshold for binary classification\n",
    "\n",
    "class_names = [\"Normal\", \"Pneumonia\"]  # Assuming 0 is Normal, 1 is Pneumonia\n",
    "\n",
    "print(f\"Predicted Class: {class_names[predicted_class]}\")\n",
    "print(f\"True Label: {class_names[int(true_label)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d687386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Define the data directories\n",
    "data_dir = \"./data\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Define image dimensions for VGGNet\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators with the correct target size for VGGNet\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fd69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vggnet(input_shape=(224, 224, 3), num_classes=1):\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), strides=2),\n",
    "\n",
    "        # Block 2\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), strides=2),\n",
    "\n",
    "        # Block 3\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), strides=2),\n",
    "\n",
    "        # Block 4\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), strides=2),\n",
    "\n",
    "        # Block 5\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), strides=2),\n",
    "\n",
    "        # Fully connected layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='sigmoid')  # For binary classification\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b763eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\.conda\\envs\\myenvirnmt\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\.conda\\envs\\myenvirnmt\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 11/163\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13:06\u001b[0m 76s/step - accuracy: 0.7075 - loss: 2.0187"
     ]
    }
   ],
   "source": [
    "# Compile the VGGNet model\n",
    "model = vggnet(input_shape=(img_width, img_height, 3))\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,  # Adjust as needed\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf3396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
